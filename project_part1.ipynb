{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Project Part 1\n","\n","[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/sgeinitz/CS39AA-project/blob/main/project_part1.ipynb)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sgeinitz/CS39AA-project/blob/main/project_part1.ipynb)\n","\n","This notebook is intended to serve as a template to complete Part 1 of the projects. Feel free to modify this notebook as needed, but be sure to have the two main parts, a) a introductory proposal section describing what it is your doing to do and where the dataset originates, and b) an exploratory analysis section that has the histograms, charts, tables, etc. that are the output from your exploratory analysis. \n","\n","__Note you will want to remove the text above, and in the markdown cells below, and replace it with your own text describing the dataset, task, exploratory steps, etc.__"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Introduction/Background\n","\n","_In this section you will describe (in English) the dataset you are using as well as the NLP problem it deals with. For example, if you are planning to use the Twitter Natural Disaster dataset, then you will describe what the data and where it came as if you were explaining it to someone who does not know anything about the data. You will then describe how this is a __text classification__ problem, and that the labels are binary (e.g. a tweet either refers to a genuine/real natural disaster, or it does not)._ \n","\n","_Overall, this should be about a paragraph of text that could be read by someone outside of our class, and they could still understand what it is your project is doing._ \n","\n","_Note that you should __not__ simply write one sentence stating, \"This project is base on the Kaggle competition: Predicting Natural Disasters with Twitter._\"\n","\n","_If you are still looking for datasets to use, consider the following resources to explore text datasets._\n","\n","* https://huggingface.co/datasets/\n","* https://www.kaggle.com/datasets\n","* https://data-flair.training/blogs/machine-learning-datasets/ \n","* https://pytorch.org/text/stable/datasets.html\n","* https://github.com/niderhoff/nlp-datasets \n","* https://medium.com/@ODSC/20-open-datasets-for-natural-language-processing-538fbfaf8e38 \n","* https://imerit.net/blog/25-best-nlp-datasets-for-machine-learning-all-pbm/ \n","\n","\n","_If you instead are planning to do a more research-oriented or applied type of project, then describe what it is that you plan to do._\n","\n","_If it is research, then what do you want to understand/explain better?_\n","\n","_If it is applied, then what it is you plan to build?_ "]},{"cell_type":"markdown","metadata":{},"source":["The data set that I am using for my NLP project is from kaggle. The data set involves a given text and the emotions that is related to that text or predicted emotion for the text. That is what I am trying to do for my project which is to determine the type of emotion that is associated with the text or predict what the emotion is based on a text that is given. This is a text classification because it classify or puts the text in a group depending on what emotion the text is giving off. It is binary because it is going to be associted to only one emotion that the text is trying to convey. Even though at times text can display more than one emotions, there is always one emotion that can be displayed more off a text. The input for this project would be a any given text and the output would be what type of emotion the text is classified as. "]},{"cell_type":"markdown","metadata":{},"source":["## 2. Exploratory Data Analysis\n","\n","_You will now load the dataset and carry out some exploratory data analysis steps to better understand what text data looks like. See the examples from class on 10/. The following links provide some good resources of exploratory analyses of text data with Python._\n","\n","\n","* https://neptune.ai/blog/exploratory-data-analysis-natural-language-processing-tools\n","* https://regenerativetoday.com/exploratory-data-analysis-of-text-data-including-visualization-and-sentiment-analysis/\n","* https://medium.com/swlh/text-summarization-guide-exploratory-data-analysis-on-text-data-4e22ce2dd6ad  \n","* https://www.kdnuggets.com/2019/05/complete-exploratory-data-analysis-visualization-text-data.html  \n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'numpy'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# This Python 3 environment comes with many helpful analytics libraries installed\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# For example, here's several helpful packages to load\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \u001b[38;5;66;03m# linear algebra\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \u001b[38;5;66;03m# data processing, CSV file I/O (e.g. pd.read_csv)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Input data files are available in the read-only \"../input/\" directory\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\u001b[39;00m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data = pd.read_csv('/kaggle/input/emotion/Emotion_final.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data.head()"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.7 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":2}
